[
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Data Analysis",
    "section": "",
    "text": "import pandas as pd\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom IPython.display import display\nimport seaborn as sns\nsns.set_theme(style=\"whitegrid\")\n\nos.makedirs(\"figures\", exist_ok=True)\n\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\")\nprint(\"Columns in dataset:\", df.columns.tolist())\n\n# drop irrelevant columns\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\ndf.drop(columns=columns_to_drop, inplace=True, errors=\"ignore\")\n\n# Missing values heatmap\nplt.figure(figsize=(10,6))\nmsno.heatmap(df)\nplt.title(\"Missing Values Heatmap\")\nplt.tight_layout()\nplt.savefig(\"figures/missing_values_heatmap.png\", dpi=300, bbox_inches=\"tight\")\ndisplay(plt.gcf())\nplt.close()\n\nsalary_related = [\"SALARY\", \"Salary\", \"Average_Salary\", \"AVERAGE_SALARY\", \"SALARY_FROM\", \"SALARY_TO\"]\nthresh = len(df) * 0.5\ndf = df.loc[:, (df.notna().sum() &gt;= thresh) | (df.columns.isin(salary_related))]\n\n# numeric vs categorical cleaning\nnum_cols = df.select_dtypes(include=[np.number]).columns.tolist()\ncat_cols = [c for c in df.columns if c not in num_cols]\nfor c in num_cols:\n    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\nfor c in cat_cols:\n    df[c] = df[c].fillna(\"Unknown\")\n\nif \"SALARY_FROM\" in df.columns and \"SALARY_TO\" in df.columns:\n    df[\"AVG_SALARY\"] = (\n        pd.to_numeric(df[\"SALARY_FROM\"], errors=\"coerce\") +\n        pd.to_numeric(df[\"SALARY_TO\"], errors=\"coerce\")\n    ) / 2\n\nsalary_candidates = [\"AVG_SALARY\", \"SALARY\", \"Salary\", \"Average_Salary\", \"AVERAGE_SALARY\"]\nsalary_col = next((c for c in salary_candidates if c in df.columns), None)\n\nif salary_col:\n    df[salary_col] = pd.to_numeric(df[salary_col], errors=\"coerce\")\n    q1, q3 = df[salary_col].quantile([0.25, 0.75])\n    iqr = q3 - q1\n    lo, hi = q1 - 1.5*iqr, q3 + 1.5*iqr\n    df[salary_col] = df[salary_col].clip(lower=lo, upper=hi)\n\nprint(\"Detected salary_col:\", salary_col)\n\ndup_keys = [c for c in [\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"] if c in df.columns]\nif dup_keys:\n    before = len(df)\n    df = df.drop_duplicates(subset=dup_keys, keep=\"first\")\n    after = len(df)\n    print(f\"Removed duplicates: {before - after}\")\nelse:\n    df = df.drop_duplicates()\n\n/tmp/ipykernel_8371/3896394006.py:12: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\nColumns in dataset: ['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n\n\n\n\n\n\n\n\n\nDetected salary_col: AVG_SALARY\nRemoved duplicates: 3300\n\n\n/tmp/ipykernel_8371/3896394006.py:46: PerformanceWarning:\n\nDataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n\n\n\n&lt;Figure size 960x576 with 0 Axes&gt;"
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "ad688-employability-Fa2501-group12",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom IPython.display import display\n\n\nsns.set_theme(style=\"whitegrid\", palette=\"muted\")\ndf = pd.read_csv(\"data/lightcast_job_postings.csv\", low_memory=False)\n\n\n# Salary setup\nif \"SALARY_FROM\" in df.columns and \"SALARY_TO\" in df.columns:\n    df[\"AVG_SALARY\"] = (\n        pd.to_numeric(df[\"SALARY_FROM\"], errors=\"coerce\") +\n        pd.to_numeric(df[\"SALARY_TO\"], errors=\"coerce\")\n    ) / 2\n\nsalary_candidates = [\"AVG_SALARY\", \"SALARY\", \"Average_Salary\", \"AVERAGE_SALARY\"]\nsalary_col = next((c for c in salary_candidates if c in df.columns), None)\n\n# Industry setup\nindustry_candidates = [\"Industry\", \"NAICS_2022_4_NAME\", \"LIGHTCAST_SECTORS_NAME\"]\nindustry_col = next((c for c in industry_candidates if c in df.columns), None)\n\nprint(\"Detected salary_col:\", salary_col)\nprint(\"Detected industry_col:\", industry_col)\n\nDetected salary_col: AVG_SALARY\nDetected industry_col: NAICS_2022_4_NAME\n\n\n\n# Job postings by Industry\nif industry_col:\n    plt.figure(figsize=(10,5))\n    df[industry_col].value_counts().head(15).plot(kind=\"bar\")\n    plt.title(f\"Job Postings by {industry_col} (Top 15)\")\n    plt.xlabel(industry_col)\n    plt.ylabel(\"Count\")\n    plt.tight_layout()\n    plt.savefig(\"figures/job_postings_by_industry.png\", dpi=300, bbox_inches=\"tight\")\n    display(plt.gcf())\n    plt.close()\n\n/tmp/ipykernel_7737/121335137.py:8: UserWarning:\n\nTight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n\n\n\n\n\n\n\n\n\n\nAnalysis Computer Systems Design and Related Services accounts for the largest number of job postings, followed by Management, Scientific, and Technical Consulting Services. This indicates that the technology and consulting industries are currently the primary sectors for hiring. Job opportunities are primarily concentrated in areas related to digital transformation and information technology.\n\n# Salary distribution by Industry\nif salary_col and industry_col:\n    df[salary_col] = pd.to_numeric(df[salary_col], errors=\"coerce\")\n    tmp = df[[industry_col, salary_col]].dropna()\n\n    if not tmp.empty:\n        top_ind = tmp[industry_col].value_counts().head(10).index\n        tmp = tmp[tmp[industry_col].isin(top_ind)]\n\n        plt.figure(figsize=(14,8)) \n        tmp.boxplot(column=salary_col, by=industry_col)\n\n        plt.title(f\"Salary Distribution by {industry_col} ({salary_col})\", fontsize=14)\n        plt.suptitle(\"\")\n        plt.xlabel(\"Industry\", fontsize=12)\n        plt.ylabel(\"Salary\", fontsize=12)\n        plt.xticks(rotation=30, ha=\"right\", fontsize=10)\n        plt.tight_layout()\n        plt.savefig(\"figures/salary_distribution_by_industry.png\", dpi=300, bbox_inches=\"tight\")\n        display(plt.gcf())\n        plt.close()\n\n\n\n\n\n\n\n\n&lt;Figure size 1344x768 with 0 Axes&gt;\n\n\nAnalysis Salary distribution shows that finance, healthcare, and consulting industries have relatively high salaries, while traditional industries like education and accounting have relatively concentrated salaries with a lower range. However, there is a large dispersion in salaries in financial services, indicating that there are many high-paying positions but overall competition is fierce.\n\n# Remote vs On-site\nremote_col = next((c for c in [\"REMOTE_TYPE_NAME\",\"REMOTE_TYPE\",\"Remote_Type\",\"REMOTE_GROUP\"] if c in df.columns), None)\nif remote_col:\n    plt.figure(figsize=(6,6))\n    df[remote_col].fillna(\"Unknown\").value_counts().plot(kind=\"pie\", autopct=\"%1.1f%%\")\n    plt.title(\"Remote vs. On-Site Jobs\")\n    plt.ylabel(\"\")\n    plt.tight_layout()\n    plt.savefig(\"figures/remote_vs_onsite.png\", dpi=300, bbox_inches=\"tight\")\n    display(plt.gcf())\n    plt.close()\n\nprint(\"Final Columns:\", df.columns.tolist())\n\n\n\n\n\n\n\n\nFinal Columns: ['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME', 'AVG_SALARY']\n\n\nAnalysis Remote work accounts for approximately 17%, while traditional on-site work still accounts for over 70%. This suggests that while remote positions exist, most companies still maintain an offline work model. Hybrid remote work accounts for a small percentage and is not currently supported by companies, but it may become a trend in the future.\nSummary This EDA reveals the following:\n\nHiring is concentrated in the IT and consulting industries, demonstrating a clear demand for digital transformation.\nSalaries in finance and healthcare are high and fluctuate widely, indicating fierce competition for certain positions within these sectors.\nRemote positions remain a minority, but their growth potential warrants attention."
  },
  {
    "objectID": "skill_gap_analysis.html",
    "href": "skill_gap_analysis.html",
    "title": "Skill Gap Analysis",
    "section": "",
    "text": "import pandas as pd\nimport seaborn as sns\nsns.set_theme(style=\"whitegrid\")\nimport matplotlib.pyplot as plt\nimport os\nos.makedirs(\"figures\", exist_ok=True)\n\n\nBuild Team Skill DataFrame\n\nskills_data = {\n    \"Name\": [\"Yibei\", \"Fuhan\", \"Jonathan\"],\n    \"Python\": [4, 3, 2],\n    \"SQL\": [3, 4, 2],\n    \"Machine Learning\": [4, 4, 4],\n    \"Cloud Computing\": [1, 2, 3],\n    \"Communication\": [2,4,3],\n    \"Problem Solving\": [4,5,4],\n    \"Leadership\": [3,4,2]\n}\n\ndf_skills = pd.DataFrame(skills_data).set_index(\"Name\")\ndf_skills\n\nplt.figure(figsize=(6,4))\nsns.heatmap(df_skills, annot=True, cmap=\"Blues\", cbar=True)\nplt.title(\"Team Skill Ratings (1=Beginner, 5=Expert)\")\nplt.tight_layout()\nplt.savefig(\"figures/team_skill_heatmap.png\", dpi=300, bbox_inches=\"tight\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nExtract Top Industry Skills\n\njob_posts = pd.read_csv(\"data/lightcast_job_postings.csv\", low_memory=False)\n\nif \"SKILLS_NAME\" in job_posts.columns:\n    all_skills = job_posts[\"SKILLS_NAME\"].dropna().astype(str).str.split(\",\")\n    flat_skills = [s.strip().strip('\"') for sublist in all_skills for s in sublist]\n    top_job_skills = pd.Series(flat_skills).value_counts().head(10)\nelse:\n    top_job_skills = pd.Series([])\n\nprint(\"Top 10 Industry Skills from Job Postings:\")\nprint(top_job_skills)\n\nTop 10 Industry Skills from Job Postings:\nCommunication                 30768\nData Analysis                 26797\nManagement                    21274\nSQL (Programming Language)    20943\nLeadership                    17535\nProblem Solving               16553\nOperations                    14684\nProject Management            13609\nBusiness Process              13203\nBusiness Requirements         12977\nName: count, dtype: int64\n\n\n\n\nCompare Team vs Industry Skills\n\nrename_map = {\n    \"SQL\": \"SQL (Programming Language)\",\n    \"Python\": \"Data Analysis\",          \n    \"Machine Learning\": \"Data Analysis\",\n    \"Cloud Computing\": \"Operations\",    \n    \"Communication\": \"Communication\",\n    \"Problem Sloving\": \"Problem Solving\",\n    \"leadership\": \"Leadership\"\n}\n\nteam_skills = set([rename_map.get(c, c) for c in df_skills.columns])\nindustry_skills = set(top_job_skills.index)\ncovered_skills = industry_skills & team_skills\nmissing_skills = industry_skills - team_skills\n\nprint(\"✅ Covered Skills:\", covered_skills)\nprint(\"⚠️ Missing Skills:\", missing_skills)\n\nskill_coverage = pd.DataFrame({\n    \"Skill\": list(industry_skills),\n    \"Covered_by_Team\": [\"Yes\" if s in covered_skills else \"No\" for s in industry_skills]\n})\nskill_coverage[\"Covered_Value\"] = skill_coverage[\"Covered_by_Team\"].map({\"Yes\": 1, \"No\": 0}).astype(int)\nskill_coverage[\"Plot_Value\"] = skill_coverage[\"Covered_Value\"].replace(0, 0.01)\n\nplt.figure(figsize=(12,6))\nax = sns.barplot(\n    data=skill_coverage, \n    x=\"Skill\", \n    y=\"Plot_Value\", \n    hue=\"Covered_by_Team\", \n    dodge=False, \n    palette={\"Yes\":\"#4CAF50\", \"No\":\"#F08080\"}\n)\n\nfor i, row in skill_coverage.iterrows():\n    ax.text(i, row[\"Plot_Value\"]+0.05, row[\"Covered_by_Team\"], \n            ha=\"center\", va=\"bottom\", fontsize=9)\n\nplt.xticks(rotation=45, ha=\"right\")\nplt.title(\"Team Coverage of Top 10 Industry Skills\")\nplt.ylabel(\"Covered (1=Yes, 0=No)\")\nplt.ylim(0,1.3)\nplt.tight_layout()\nplt.savefig(\"figures/skill_gap_analysis.png\", dpi=300, bbox_inches=\"tight\")\nplt.show()\n\ncoverage_rate = len(covered_skills) / len(industry_skills) * 100\nplt.figure(figsize=(5,4))\nplt.bar([\"Coverage Rate\"], [coverage_rate], color=\"#FFB6C1\")\nplt.ylabel(\"Coverage (%)\")\nplt.ylim(0,100)\nplt.title(\"Overall Team Coverage Rate\")\nplt.text(0, coverage_rate/2, f\"{coverage_rate:.1f}%\", \n         ha=\"center\", va=\"center\", fontsize=12, color=\"black\")\nplt.savefig(\"figures/coverage_rate.png\", dpi=300, bbox_inches=\"tight\")\nplt.show()\n\nmapping_table = pd.DataFrame({\n    \"Team Skill\": df_skills.columns,\n    \"Mapped Industry Skill\": [rename_map.get(c, c) for c in df_skills.columns],\n    \"In Top 10\": [\"Yes\" if rename_map.get(c, c) in industry_skills else \"No\" for c in df_skills.columns]\n})\ndisplay(mapping_table)\n\n✅ Covered Skills: {'Communication', 'SQL (Programming Language)', 'Data Analysis', 'Leadership', 'Operations', 'Problem Solving'}\n⚠️ Missing Skills: {'Management', 'Project Management', 'Business Process', 'Business Requirements'}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTeam Skill\nMapped Industry Skill\nIn Top 10\n\n\n\n\n0\nPython\nData Analysis\nYes\n\n\n1\nSQL\nSQL (Programming Language)\nYes\n\n\n2\nMachine Learning\nData Analysis\nYes\n\n\n3\nCloud Computing\nOperations\nYes\n\n\n4\nCommunication\nCommunication\nYes\n\n\n5\nProblem Solving\nProblem Solving\nYes\n\n\n6\nLeadership\nLeadership\nYes\n\n\n\n\n\n\n\nResults and Improvement Plan Our team analyzed and compared their self-assessed skills scores with the top ten most in-demand industry skills extracted from job postings. The results showed strong coverage across technical areas, particularly in data analytics, SQL, and operations, with Python, programming languages, and cloud computing as the foundation. These skills align closely with market demand and position the team well for data-centric and technical roles.\nHowever, the analysis also revealed significant shortcomings. The team lacked formal expertise in project management, business needs, and leadership. While corporate HR departments consistently emphasize these areas as crucial for roles bridging technology and business, particularly in managing teams or translating technology solutions into business value, our overall coverage was 60%, highlighting significant room for improvement.\nImprovement Plan While our team has certain strengths in technical skills like data analysis, SQL, and cloud computing, a comparison with industry requirements reveals significant shortcomings. Project management, business needs analysis, and communication are particularly important skills that recruiters value most, yet they are currently largely absent within our team. Therefore, if we aspire to take on more comprehensive roles in the future, relying solely on technical proficiency will not be enough.\nTo address our shortcomings, we need to proactively develop these soft skills. For example, in class group assignments, we can try creating a project coordination role to hone project management and communication skills through practical experience. Outside of class, we can leverage BU resources to participate in projects and courses related to Project Management and Business Process Management to enhance these skills. Leadership is also a weakness worth addressing. While each of us has demonstrated organizational skills to varying degrees, our overall level is still insufficient. This can be developed through rotating leadership roles within the group.\nIn the long run, we must not only maintain our edge in data analysis and technology but also gradually build a comprehensive capability structure that encompasses both software and hardware. This will allow us to secure the jobs we desire in a highly competitive job market. Furthermore, we will be able to not only produce technical achievements at work but also drive projects to fruition."
  },
  {
    "objectID": "regression_classification.html",
    "href": "regression_classification.html",
    "title": "Regression, Classification, and Topic Insights",
    "section": "",
    "text": "import pandas as pd\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom IPython.display import display\nimport seaborn as sns\nsns.set_theme(style=\"whitegrid\")\n\nos.makedirs(\"figures\", exist_ok=True)\n\ncsv_path = \"data/lightcast_job_postings.csv\"\nif not os.path.exists(csv_path):\n  print(f\"Data file not found: {csv_path}\")\n  print(\"Place the dataset in the `data/` folder or update the path. Skipping data load.\")\n  df = None\nelse:\n  df = pd.read_csv(csv_path)\n  print(\"Columns in dataset:\", df.columns.tolist())\n# close previous python block and start a new one for analysis\n\n/var/folders/mb/jgg053s522lbkfwkckr1sylh0000gn/T/ipykernel_86632/951617275.py:18: DtypeWarning:\n\nColumns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n\n\n\nColumns in dataset: ['ID', 'LAST_UPDATED_DATE', 'LAST_UPDATED_TIMESTAMP', 'DUPLICATES', 'POSTED', 'EXPIRED', 'DURATION', 'SOURCE_TYPES', 'SOURCES', 'URL', 'ACTIVE_URLS', 'ACTIVE_SOURCES_INFO', 'TITLE_RAW', 'BODY', 'MODELED_EXPIRED', 'MODELED_DURATION', 'COMPANY', 'COMPANY_NAME', 'COMPANY_RAW', 'COMPANY_IS_STAFFING', 'EDUCATION_LEVELS', 'EDUCATION_LEVELS_NAME', 'MIN_EDULEVELS', 'MIN_EDULEVELS_NAME', 'MAX_EDULEVELS', 'MAX_EDULEVELS_NAME', 'EMPLOYMENT_TYPE', 'EMPLOYMENT_TYPE_NAME', 'MIN_YEARS_EXPERIENCE', 'MAX_YEARS_EXPERIENCE', 'IS_INTERNSHIP', 'SALARY', 'REMOTE_TYPE', 'REMOTE_TYPE_NAME', 'ORIGINAL_PAY_PERIOD', 'SALARY_TO', 'SALARY_FROM', 'LOCATION', 'CITY', 'CITY_NAME', 'COUNTY', 'COUNTY_NAME', 'MSA', 'MSA_NAME', 'STATE', 'STATE_NAME', 'COUNTY_OUTGOING', 'COUNTY_NAME_OUTGOING', 'COUNTY_INCOMING', 'COUNTY_NAME_INCOMING', 'MSA_OUTGOING', 'MSA_NAME_OUTGOING', 'MSA_INCOMING', 'MSA_NAME_INCOMING', 'NAICS2', 'NAICS2_NAME', 'NAICS3', 'NAICS3_NAME', 'NAICS4', 'NAICS4_NAME', 'NAICS5', 'NAICS5_NAME', 'NAICS6', 'NAICS6_NAME', 'TITLE', 'TITLE_NAME', 'TITLE_CLEAN', 'SKILLS', 'SKILLS_NAME', 'SPECIALIZED_SKILLS', 'SPECIALIZED_SKILLS_NAME', 'CERTIFICATIONS', 'CERTIFICATIONS_NAME', 'COMMON_SKILLS', 'COMMON_SKILLS_NAME', 'SOFTWARE_SKILLS', 'SOFTWARE_SKILLS_NAME', 'ONET', 'ONET_NAME', 'ONET_2019', 'ONET_2019_NAME', 'CIP6', 'CIP6_NAME', 'CIP4', 'CIP4_NAME', 'CIP2', 'CIP2_NAME', 'SOC_2021_2', 'SOC_2021_2_NAME', 'SOC_2021_3', 'SOC_2021_3_NAME', 'SOC_2021_4', 'SOC_2021_4_NAME', 'SOC_2021_5', 'SOC_2021_5_NAME', 'LOT_CAREER_AREA', 'LOT_CAREER_AREA_NAME', 'LOT_OCCUPATION', 'LOT_OCCUPATION_NAME', 'LOT_SPECIALIZED_OCCUPATION', 'LOT_SPECIALIZED_OCCUPATION_NAME', 'LOT_OCCUPATION_GROUP', 'LOT_OCCUPATION_GROUP_NAME', 'LOT_V6_SPECIALIZED_OCCUPATION', 'LOT_V6_SPECIALIZED_OCCUPATION_NAME', 'LOT_V6_OCCUPATION', 'LOT_V6_OCCUPATION_NAME', 'LOT_V6_OCCUPATION_GROUP', 'LOT_V6_OCCUPATION_GROUP_NAME', 'LOT_V6_CAREER_AREA', 'LOT_V6_CAREER_AREA_NAME', 'SOC_2', 'SOC_2_NAME', 'SOC_3', 'SOC_3_NAME', 'SOC_4', 'SOC_4_NAME', 'SOC_5', 'SOC_5_NAME', 'LIGHTCAST_SECTORS', 'LIGHTCAST_SECTORS_NAME', 'NAICS_2022_2', 'NAICS_2022_2_NAME', 'NAICS_2022_3', 'NAICS_2022_3_NAME', 'NAICS_2022_4', 'NAICS_2022_4_NAME', 'NAICS_2022_5', 'NAICS_2022_5_NAME', 'NAICS_2022_6', 'NAICS_2022_6_NAME']\n\n\n\n# --- classify ML/Data-Science skills and cluster by salary ---\nimport re\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\n\ndef safe_tokens(val):\n  if pd.isna(val):\n    return []\n  s = str(val)\n  # handle Python lists\n  try:\n    import ast\n    parsed = ast.literal_eval(s)\n    if isinstance(parsed, (list, tuple, set)):\n      return [str(x).strip() for x in parsed if x not in (None, '')]\n  except Exception:\n    pass\n  # split on common separators\n  parts = re.split(r\"\\||;|\\\\n|\\\\r|\\\\t|,\", s)\n  return [p.strip().strip('\\\"\\'') for p in parts if p.strip()]\n\n# keywords to mark ML/DS-related skills\nml_keywords = [\n  'machine learning','data science','deep learning','neural','tensorflow','pytorch',\n  'scikit','sklearn','xgboost','lightgbm','pandas','numpy','nlp','natural language',\n  'computer vision','keras','statistics','statistical','rnn','cnn'\n]\n\ndef count_ml_tokens(tokens):\n  cnt = 0\n  for t in tokens:\n    low = t.lower()\n    for k in ml_keywords:\n      if k in low:\n        cnt += 1\n        break\n  return cnt\n\n# combine several skill/name columns to form a token set per posting\nskill_cols = ['SKILLS_NAME','SPECIALIZED_SKILLS_NAME','COMMON_SKILLS_NAME','SOFTWARE_SKILLS_NAME']\nfor c in skill_cols:\n  if c not in df.columns:\n    df[c] = None\n\ndef build_tokens_row(row):\n  toks = []\n  for c in skill_cols:\n    toks.extend(safe_tokens(row.get(c, '')))\n  return toks\n\ndf['all_skill_tokens'] = df.apply(build_tokens_row, axis=1)\ndf['ml_skill_count'] = df['all_skill_tokens'].apply(count_ml_tokens)\ndf['n_skills'] = df['all_skill_tokens'].apply(len)\n\n# build a salary numeric column: prefer SALARY (if present) else average of SALARY_FROM/SALARY_TO\nif 'SALARY' in df.columns:\n  df['salary_num'] = pd.to_numeric(df['SALARY'], errors='coerce')\nelse:\n  sf = pd.to_numeric(df.get('SALARY_FROM', pd.Series([None]*len(df))), errors='coerce')\n  st = pd.to_numeric(df.get('SALARY_TO', pd.Series([None]*len(df))), errors='coerce')\n  df['salary_num'] = sf\n  # if both available, take mean\n  df.loc[~sf.isna() & ~st.isna(), 'salary_num'] = (sf + st)/2\n\n# keep rows with a positive salary\ndf_model = df[df['salary_num'].notna() & (df['salary_num']&gt;0)].copy()\nif df_model.shape[0] == 0:\n  print('No salary data available for clustering.')\nelse:\n  X = df_model[['salary_num','ml_skill_count','n_skills']].fillna(0).to_numpy()\n  scaler = StandardScaler()\n  Xs = scaler.fit_transform(X)\n\n  # cluster into 2 groups (we'll map one group to ML jobs and the other to non-ML)\n  kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n  labels = kmeans.fit_predict(Xs)\n  df_model['cluster'] = labels\n\n  # mark ML job by whether it has any ML tokens\n  df_model['is_ml_job'] = df_model['ml_skill_count']&gt;0\n\n  # determine which cluster has the higher proportion of ML jobs and label clusters accordingly\n  try:\n    cluster_ml_pct = df_model.groupby('cluster')['is_ml_job'].mean()\n    if not cluster_ml_pct.empty:\n      ml_cluster = int(cluster_ml_pct.idxmax())\n    else:\n      ml_cluster = 1\n  except Exception:\n    ml_cluster = 1\n  df_model['cluster_is_ml'] = df_model['cluster'].apply(lambda c: c == ml_cluster)\n  df_model['cluster_label'] = df_model['cluster_is_ml'].map({True: 'ML cluster', False: 'Non-ML cluster'})\n\n  # summarize clusters\n  summary = df_model.groupby('cluster').agg(\n    postings=('cluster','size'),\n    avg_salary=('salary_num','mean'),\n    median_salary=('salary_num','median'),\n    avg_ml_skill_count=('ml_skill_count','mean'),\n    pct_ml_jobs=('is_ml_job', lambda x: 100*x.mean())\n  ).sort_index()\n\n  print('\\nCluster summary (salary and ML presence):')\n  print(summary)\n\n  # show cluster centers in original feature space\n  centers = scaler.inverse_transform(kmeans.cluster_centers_)\n  print('\\nCluster centers (salary_num, ml_skill_count, n_skills):')\n  for i,c in enumerate(centers):\n    print(f'Cluster {i}:', c)\n\n  # show top 10 sample postings per cluster that are ML jobs\n  for i in sorted(df_model['cluster'].unique()):\n    print('\\n' + '='*40)\n    print(f'Cluster {i} — top ML postings (sample)')\n    sample = df_model[(df_model['cluster']==i) & (df_model['is_ml_job'])].head(10)\n    if sample.empty:\n      print('  (no ML postings in this cluster)')\n    else:\n      for idx,row in sample.iterrows():\n        title = row.get('TITLE') or row.get('TITLE_NAME') or ''\n        print(f\"  id={row.get('ID')} | salary={row.get('salary_num'):.0f} | ml_count={row.get('ml_skill_count')} | title={title}\")\n\n\nCluster summary (salary and ML presence):\n         postings     avg_salary  median_salary  avg_ml_skill_count  \\\ncluster                                                               \n0           20496  107614.271858       106080.0            0.305328   \n1           10312  138504.380237       133700.0            2.484678   \n\n         pct_ml_jobs  \ncluster               \n0          12.987900  \n1          52.269201  \n\nCluster centers (salary_num, ml_skill_count, n_skills):\nCluster 0: [1.07642300e+05 3.05321173e-01 3.73175633e+01]\nCluster 1: [1.38469598e+05 2.48617176e+00 8.37555556e+01]\n\n========================================\nCluster 0 — top ML postings (sample)\n  id=2725b337958d2ca49d99a8768741e6090bc6a74d | salary=84678 | ml_count=2 | title=ETCD1DCE2110BB27EB\n  id=9608eb18fbcc70dae3f59025cca9993e89cb94a9 | salary=101798 | ml_count=2 | title=ET3037E0C947A02404\n  id=a0db3935cdbf3d42e7a79b83f6e8074b329e085b | salary=171600 | ml_count=2 | title=ETA167677FC704C4AD\n  id=b1de4586ebd2d2e67680b9c18d543dddef07e47d | salary=70880 | ml_count=2 | title=ET3037E0C947A02404\n  id=d1be2dfb08255f7fdad6b302a4190cdf5e422720 | salary=69680 | ml_count=2 | title=ET6DA4FDEAD969847C\n  id=8b445797f947f39c25b55c2c572137b71045a8ac | salary=69680 | ml_count=2 | title=ET8E0C473DFBEDF8C8\n  id=80b1483d1b8816ec99650ea778bab64adf8c50d6 | salary=69680 | ml_count=2 | title=ET6DA4FDEAD969847C\n  id=23f8f04e4a10c70f6d0a28cb74b35ba173d9a7e8 | salary=69680 | ml_count=2 | title=ETA945BF69C78F1F2B\n  id=4c6903192f71f03f304f7484b73fd4d9610b1e69 | salary=165500 | ml_count=2 | title=ET13E3A2844323866E\n  id=530c8ed958399be5655568d64c3ce2da86f20ff7 | salary=68576 | ml_count=4 | title=ET6B57FB37DA4AA8A8\n\n========================================\nCluster 1 — top ML postings (sample)\n  id=229620073766234e814e8add21db7dfaef69b3bd | salary=92962 | ml_count=8 | title=ET1CE3CFA5447376E9\n  id=f361bb10174a44d316c48ac7ce669390abbf7c7b | salary=136950 | ml_count=15 | title=ET5AA72D0E18D0EFE5\n  id=146621e071735303b16f75333b8593fb3f245ea0 | salary=118560 | ml_count=6 | title=ET0000000000000000\n  id=9ec8abde1f4b88863ec96b3523e03f0a39b2e5bf | salary=140756 | ml_count=13 | title=ET9B37BAEB716CCCDA\n  id=e68a72d999879ef6969e57be84023c6243716bdc | salary=156038 | ml_count=19 | title=ET00335BE0181594E1\n  id=2e9acb4dfcf3979abcb892fdb02e8792cfc74a04 | salary=161840 | ml_count=4 | title=ETC1360A6DCAF5E713\n  id=2b9cd1c2f0413e5eee667a0e785f131f3ab50817 | salary=103573 | ml_count=4 | title=ET808060B2DD7A4902\n  id=ea8bc28ca5f1e012159fa50e4a17947270431a9a | salary=122500 | ml_count=2 | title=ET3037E0C947A02404\n  id=5575c78b966843a96790769924eb8c5335367e23 | salary=71000 | ml_count=8 | title=ET3037E0C947A02404\n  id=0625296f2e6627c2261bf27e634bad063442d1de | salary=76460 | ml_count=4 | title=ET29293A7C0D786B75\n\n\n\n# --- Static Matplotlib KMeans scatter: salary (y, log) vs cluster (x jitter), color by NAICS group, outline for ML jobs ---\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.ticker import FuncFormatter\nimport math\n\nplot_df = df_model[df_model['salary_num'].notna() & (df_model['salary_num']&gt;0)].copy()\nif plot_df.empty:\n  print('No salary data available for static plotting.')\nelse:\n  if 'cluster' not in plot_df.columns:\n    from sklearn.cluster import KMeans\n    from sklearn.preprocessing import StandardScaler\n    X = plot_df[['salary_num','ml_skill_count','n_skills']].fillna(0).to_numpy()\n    sc = StandardScaler(); Xs = sc.fit_transform(X)\n    kmeans_tmp = KMeans(n_clusters=2, random_state=42, n_init=10).fit(Xs)\n    plot_df['cluster'] = kmeans_tmp.labels_\n    # map which temporary cluster is ML-heavy\n    try:\n      tmp_ml_pct = plot_df.groupby('cluster')['ml_skill_count'].apply(lambda s: (s&gt;0).mean())\n      tmp_ml_cluster = int(tmp_ml_pct.idxmax())\n    except Exception:\n      tmp_ml_cluster = 1\n    plot_df['cluster_is_ml'] = plot_df['cluster'].apply(lambda c: c == tmp_ml_cluster)\n    plot_df['cluster'] = plot_df['cluster_is_ml'].astype(int)\n\n  # Robust NAICS/industry column detection (case-insensitive). Prefer name/title/description columns.\n  import re as _re\n  cols = list(plot_df.columns)\n  naics_like = [c for c in cols if _re.search(r'naics|industry', c, _re.I)]\n  naics_name_cols = [c for c in naics_like if _re.search(r'name|title|desc|sector', c, _re.I)]\n  naics_code_cols = [c for c in naics_like if _re.search(r'code|id|num|^naics$', c, _re.I)]\n\n  if naics_name_cols:\n    naics_col = naics_name_cols[0]\n    plot_df['naics_group'] = plot_df[naics_col].fillna('Unknown').astype(str)\n  elif naics_like and naics_code_cols:\n    # prefer code column if only codes are present\n    code_col = naics_code_cols[0]\n    plot_df['naics_group'] = plot_df[code_col].fillna('Unknown').astype(str).apply(lambda v: f\"NAICS {v}\" if str(v).strip()!='' else 'Unknown')\n  elif naics_like:\n    # fallback: use first matching column\n    naics_col = naics_like[0]\n    plot_df['naics_group'] = plot_df[naics_col].fillna('Unknown').astype(str)\n  else:\n    plot_df['naics_group'] = 'Unknown'\n\n  top_naics = plot_df['naics_group'].value_counts().nlargest(10).index.tolist()\n  plot_df['naics_top'] = plot_df['naics_group'].where(plot_df['naics_group'].isin(top_naics), 'Other')\n\n  plot_df['ml_flag'] = plot_df['is_ml_job']\n  rng = np.random.default_rng(6)\n  plot_df['x_jitter'] = plot_df['cluster'].astype(int) + rng.normal(0, 0.12, size=len(plot_df))\n\n  # sample for plotting to keep figure readable\n  sample_df = plot_df.sample(n=min(20000, len(plot_df)), random_state=7)\n\n  plt.figure(figsize=(12,8))\n  groups = sample_df.groupby('naics_top')\n  cmap = plt.get_cmap('tab10')\n  colors = {g: cmap(i % 10) for i,g in enumerate(groups.groups.keys())}\n\n  for g, sub in groups:\n    plt.scatter(sub['x_jitter'], sub['salary_num'], s=18, alpha=0.65, label=g, color=colors[g])\n\n  # outline ML jobs (do not add a legend entry for the outline)\n  ml_sub = sample_df[sample_df['ml_flag']]\n  plt.scatter(ml_sub['x_jitter'], ml_sub['salary_num'], facecolors='none', edgecolors='k', s=45, linewidths=0.6)\n\n  # Use linear scale so we can show dollar ticks every $25,000 as requested\n  plt.yscale('linear')\n  plt.xlabel('KMeans cluster (jittered)')\n  plt.ylabel('Salary (USD, log scale)')\n  plt.title('KMeans clusters: Salary by NAICS group; ML jobs outlined')\n  # Label x-axis clusters explicitly: 1 = ML jobs, 0 = Non-ML jobs\n  cluster_order = sorted(plot_df['cluster'].unique())\n  # map 1-&gt;ML cluster label\n  xtick_labels = []\n  for c in cluster_order:\n    if 'cluster_label' in plot_df.columns:\n      # use cluster_label if present\n      lab = 'Jobs Requiring ML/DS Skills' if (plot_df['cluster_label'].iloc[0] == 'ML cluster' and c==1) or (plot_df['cluster_label'].unique().size==2 and plot_df.loc[plot_df['cluster']==c,'cluster_label'].iloc[0]=='ML cluster') else 'Jobs Not Requiring ML/DS Skills'\n    else:\n      lab = 'Jobs Requiring ML/DS Skills' if c==1 else 'Jobs Not Requiring ML/DS Skills'\n    xtick_labels.append(lab)\n\n  plt.xticks(cluster_order, xtick_labels, rotation=15)\n\n  # set major y-ticks every $25,000 from min to max salary (rounded)\n  ymin = math.floor(sample_df['salary_num'].min() / 25000) * 25000\n  ymax = math.ceil(sample_df['salary_num'].max() / 25000) * 25000\n  y_ticks = list(range(int(ymin), int(ymax)+1, 25000))\n  plt.gca().set_yticks(y_ticks)\n\n  def usd(x, pos):\n    return f\"${x:,.0f}\"\n\n  plt.gca().yaxis.set_major_formatter(FuncFormatter(usd))\n  # keep legend for NAICS groups only, not the ML outline\n  plt.legend(title='NAICS (top)', bbox_to_anchor=(1.02,1), loc='upper left')\n  plt.tight_layout()\n  out_png = 'figures/kmeans_salary_naics_scatter.png'\n  plt.savefig(out_png, dpi=220)\n  print('Saved static KMeans NAICS scatter to', out_png)\n\nSaved static KMeans NAICS scatter to figures/kmeans_salary_naics_scatter.png\n\n\n\n\n\n\n\n\n\n```"
  }
]