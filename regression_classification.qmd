---
title: "Regression, Classification, and Topic Insights"
author:
  - name: Yibei Yu, Fuhan Zhang, Jonathan Leon
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
bibliography: references.bib
csl: csl/econometrica.csl
format: 
  html:
    toc: true
    number-sections: true
    df-print: paged
---
```{python}
import pandas as pd
import missingno as msno
import matplotlib.pyplot as plt
import numpy as np
import os
from IPython.display import display
import seaborn as sns
sns.set_theme(style="whitegrid")

os.makedirs("figures", exist_ok=True)

csv_path = "data/lightcast_job_postings.csv"
if not os.path.exists(csv_path):
  print(f"Data file not found: {csv_path}")
  print("Place the dataset in the `data/` folder or update the path. Skipping data load.")
  df = None
else:
  df = pd.read_csv(csv_path)
  print("Columns in dataset:", df.columns.tolist())
# close previous python block and start a new one for analysis

```

```{python}
# --- classify ML/Data-Science skills and cluster by salary ---
import re
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

def safe_tokens(val):
  if pd.isna(val):
    return []
  s = str(val)
  # handle Python lists
  try:
    import ast
    parsed = ast.literal_eval(s)
    if isinstance(parsed, (list, tuple, set)):
      return [str(x).strip() for x in parsed if x not in (None, '')]
  except Exception:
    pass
  # split on common separators
  parts = re.split(r"\||;|\\n|\\r|\\t|,", s)
  return [p.strip().strip('\"\'') for p in parts if p.strip()]

# keywords to mark ML/DS-related skills
ml_keywords = [
  'machine learning','data science','deep learning','neural','tensorflow','pytorch',
  'scikit','sklearn','xgboost','lightgbm','pandas','numpy','nlp','natural language',
  'computer vision','keras','statistics','statistical','rnn','cnn'
]

def count_ml_tokens(tokens):
  cnt = 0
  for t in tokens:
    low = t.lower()
    for k in ml_keywords:
      if k in low:
        cnt += 1
        break
  return cnt

# combine several skill/name columns to form a token set per posting
skill_cols = ['SKILLS_NAME','SPECIALIZED_SKILLS_NAME','COMMON_SKILLS_NAME','SOFTWARE_SKILLS_NAME']
for c in skill_cols:
  if c not in df.columns:
    df[c] = None

def build_tokens_row(row):
  toks = []
  for c in skill_cols:
    toks.extend(safe_tokens(row.get(c, '')))
  return toks

df['all_skill_tokens'] = df.apply(build_tokens_row, axis=1)
df['ml_skill_count'] = df['all_skill_tokens'].apply(count_ml_tokens)
df['n_skills'] = df['all_skill_tokens'].apply(len)

# build a salary numeric column: prefer SALARY (if present) else average of SALARY_FROM/SALARY_TO
if 'SALARY' in df.columns:
  df['salary_num'] = pd.to_numeric(df['SALARY'], errors='coerce')
else:
  sf = pd.to_numeric(df.get('SALARY_FROM', pd.Series([None]*len(df))), errors='coerce')
  st = pd.to_numeric(df.get('SALARY_TO', pd.Series([None]*len(df))), errors='coerce')
  df['salary_num'] = sf
  # if both available, take mean
  df.loc[~sf.isna() & ~st.isna(), 'salary_num'] = (sf + st)/2

# keep rows with a positive salary
df_model = df[df['salary_num'].notna() & (df['salary_num']>0)].copy()
if df_model.shape[0] == 0:
  print('No salary data available for clustering.')
else:
  X = df_model[['salary_num','ml_skill_count','n_skills']].fillna(0).to_numpy()
  scaler = StandardScaler()
  Xs = scaler.fit_transform(X)

  # cluster into 2 groups (we'll map one group to ML jobs and the other to non-ML)
  kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
  labels = kmeans.fit_predict(Xs)
  df_model['cluster'] = labels

  # mark ML job by whether it has any ML tokens
  df_model['is_ml_job'] = df_model['ml_skill_count']>0

  # determine which cluster has the higher proportion of ML jobs and label clusters accordingly
  try:
    cluster_ml_pct = df_model.groupby('cluster')['is_ml_job'].mean()
    if not cluster_ml_pct.empty:
      ml_cluster = int(cluster_ml_pct.idxmax())
    else:
      ml_cluster = 1
  except Exception:
    ml_cluster = 1
  df_model['cluster_is_ml'] = df_model['cluster'].apply(lambda c: c == ml_cluster)
  df_model['cluster_label'] = df_model['cluster_is_ml'].map({True: 'ML cluster', False: 'Non-ML cluster'})

  # summarize clusters
  summary = df_model.groupby('cluster').agg(
    postings=('cluster','size'),
    avg_salary=('salary_num','mean'),
    median_salary=('salary_num','median'),
    avg_ml_skill_count=('ml_skill_count','mean'),
    pct_ml_jobs=('is_ml_job', lambda x: 100*x.mean())
  ).sort_index()

  print('\nCluster summary (salary and ML presence):')
  print(summary)

  # show cluster centers in original feature space
  centers = scaler.inverse_transform(kmeans.cluster_centers_)
  print('\nCluster centers (salary_num, ml_skill_count, n_skills):')
  for i,c in enumerate(centers):
    print(f'Cluster {i}:', c)

  # show top 10 sample postings per cluster that are ML jobs
  for i in sorted(df_model['cluster'].unique()):
    print('\n' + '='*40)
    print(f'Cluster {i} — top ML postings (sample)')
    sample = df_model[(df_model['cluster']==i) & (df_model['is_ml_job'])].head(10)
    if sample.empty:
      print('  (no ML postings in this cluster)')
    else:
      for idx,row in sample.iterrows():
        title = row.get('TITLE') or row.get('TITLE_NAME') or ''
        print(f"  id={row.get('ID')} | salary={row.get('salary_num'):.0f} | ml_count={row.get('ml_skill_count')} | title={title}")

```


```{python}
# --- Static Matplotlib KMeans scatter: salary (y, log) vs cluster (x jitter), color by NAICS group, outline for ML jobs ---
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.ticker import FuncFormatter
import math

plot_df = df_model[df_model['salary_num'].notna() & (df_model['salary_num']>0)].copy()
if plot_df.empty:
  print('No salary data available for static plotting.')
else:
  if 'cluster' not in plot_df.columns:
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    X = plot_df[['salary_num','ml_skill_count','n_skills']].fillna(0).to_numpy()
    sc = StandardScaler(); Xs = sc.fit_transform(X)
    kmeans_tmp = KMeans(n_clusters=2, random_state=42, n_init=10).fit(Xs)
    plot_df['cluster'] = kmeans_tmp.labels_
    # map which temporary cluster is ML-heavy
    try:
      tmp_ml_pct = plot_df.groupby('cluster')['ml_skill_count'].apply(lambda s: (s>0).mean())
      tmp_ml_cluster = int(tmp_ml_pct.idxmax())
    except Exception:
      tmp_ml_cluster = 1
    plot_df['cluster_is_ml'] = plot_df['cluster'].apply(lambda c: c == tmp_ml_cluster)
    plot_df['cluster'] = plot_df['cluster_is_ml'].astype(int)

  # Robust NAICS/industry column detection (case-insensitive). Prefer name/title/description columns.
  import re as _re
  cols = list(plot_df.columns)
  naics_like = [c for c in cols if _re.search(r'naics|industry', c, _re.I)]
  naics_name_cols = [c for c in naics_like if _re.search(r'name|title|desc|sector', c, _re.I)]
  naics_code_cols = [c for c in naics_like if _re.search(r'code|id|num|^naics$', c, _re.I)]

  if naics_name_cols:
    naics_col = naics_name_cols[0]
    plot_df['naics_group'] = plot_df[naics_col].fillna('Unknown').astype(str)
  elif naics_like and naics_code_cols:
    # prefer code column if only codes are present
    code_col = naics_code_cols[0]
    plot_df['naics_group'] = plot_df[code_col].fillna('Unknown').astype(str).apply(lambda v: f"NAICS {v}" if str(v).strip()!='' else 'Unknown')
  elif naics_like:
    # fallback: use first matching column
    naics_col = naics_like[0]
    plot_df['naics_group'] = plot_df[naics_col].fillna('Unknown').astype(str)
  else:
    plot_df['naics_group'] = 'Unknown'

  top_naics = plot_df['naics_group'].value_counts().nlargest(10).index.tolist()
  plot_df['naics_top'] = plot_df['naics_group'].where(plot_df['naics_group'].isin(top_naics), 'Other')

  plot_df['ml_flag'] = plot_df['is_ml_job']
  rng = np.random.default_rng(6)
  plot_df['x_jitter'] = plot_df['cluster'].astype(int) + rng.normal(0, 0.12, size=len(plot_df))

  # sample for plotting to keep figure readable
  sample_df = plot_df.sample(n=min(20000, len(plot_df)), random_state=7)

  plt.figure(figsize=(12,8))
  groups = sample_df.groupby('naics_top')
  cmap = plt.get_cmap('tab10')
  colors = {g: cmap(i % 10) for i,g in enumerate(groups.groups.keys())}

  for g, sub in groups:
    plt.scatter(sub['x_jitter'], sub['salary_num'], s=18, alpha=0.65, label=g, color=colors[g])

  # outline ML jobs (do not add a legend entry for the outline)
  ml_sub = sample_df[sample_df['ml_flag']]
  plt.scatter(ml_sub['x_jitter'], ml_sub['salary_num'], facecolors='none', edgecolors='k', s=45, linewidths=0.6)

  # Use linear scale so we can show dollar ticks every $25,000 as requested
  plt.yscale('linear')
  plt.xlabel('KMeans cluster (jittered)')
  plt.ylabel('Salary (USD, log scale)')
  plt.title('KMeans clusters: Salary by NAICS group; ML jobs outlined')
  # Label x-axis clusters explicitly: 1 = ML jobs, 0 = Non-ML jobs
  cluster_order = sorted(plot_df['cluster'].unique())
  # map 1->ML cluster label
  xtick_labels = []
  for c in cluster_order:
    if 'cluster_label' in plot_df.columns:
      # use cluster_label if present
      lab = 'Jobs Requiring ML/DS Skills' if (plot_df['cluster_label'].iloc[0] == 'ML cluster' and c==1) or (plot_df['cluster_label'].unique().size==2 and plot_df.loc[plot_df['cluster']==c,'cluster_label'].iloc[0]=='ML cluster') else 'Jobs Not Requiring ML/DS Skills'
    else:
      lab = 'Jobs Requiring ML/DS Skills' if c==1 else 'Jobs Not Requiring ML/DS Skills'
    xtick_labels.append(lab)

  plt.xticks(cluster_order, xtick_labels, rotation=15)

  # set major y-ticks every $25,000 from min to max salary (rounded)
  ymin = math.floor(sample_df['salary_num'].min() / 25000) * 25000
  ymax = math.ceil(sample_df['salary_num'].max() / 25000) * 25000
  y_ticks = list(range(int(ymin), int(ymax)+1, 25000))
  plt.gca().set_yticks(y_ticks)

  def usd(x, pos):
    return f"${x:,.0f}"

  plt.gca().yaxis.set_major_formatter(FuncFormatter(usd))
  # keep legend for NAICS groups only, not the ML outline
  plt.legend(title='NAICS (top)', bbox_to_anchor=(1.02,1), loc='upper left')
  plt.tight_layout()
  out_png = 'figures/kmeans_salary_naics_scatter.png'
  plt.savefig(out_png, dpi=220)
  print('Saved static KMeans NAICS scatter to', out_png)

```

# Analysis
The KMeans clustering was run comparing positions that specifically required machine learning or data science skills against those that did not, with identifiers for the top ten industry segments and all others grouped as “Other.” If all positions had been plotted together, it appears there would have been a natural split around the $225,000 salary mark, as postings above that threshold become increasingly sparse. Looking at the two clusters side by side, it’s clear that while both include outliers, roles requiring machine learning or data science skills have not only a higher concentration of positions above the $225,000 mark but also significantly more extreme salary outliers.


```{python}
# --- Multiple linear regression: log(salary) on ML-job indicator, industry fixed effects, and controls ---
import statsmodels.formula.api as smf
import statsmodels.api as sm

# prefer df_model if available (created during clustering); otherwise fall back to plot_df
source_df = None
if 'df_model' in globals():
  source_df = df_model.copy()
elif 'plot_df' in globals():
  source_df = plot_df.copy()
else:
  source_df = df.copy()

# ensure salary numeric present
if source_df is None or source_df.empty or 'salary_num' not in source_df.columns:
  print('No usable salary data available for regression.')
else:
  df_reg = source_df[source_df['salary_num'].notna() & (source_df['salary_num']>0)].copy()
  if df_reg.empty:
    print('No salary rows after filtering for regression.')
  else:
    # detect NAICS/industry column robustly (same approach as plotting)
    import re as _re
    cols = list(df_reg.columns)
    naics_like = [c for c in cols if _re.search(r'naics|industry', c, _re.I)]
    naics_name_cols = [c for c in naics_like if _re.search(r'name|title|desc|sector', c, _re.I)]
    naics_code_cols = [c for c in naics_like if _re.search(r'code|id|num|^naics$', c, _re.I)]

    if naics_name_cols:
      naics_col = naics_name_cols[0]
      df_reg['naics_group'] = df_reg[naics_col].fillna('Unknown').astype(str)
    elif naics_like and naics_code_cols:
      code_col = naics_code_cols[0]
      df_reg['naics_group'] = df_reg[code_col].fillna('Unknown').astype(str).apply(lambda v: f"NAICS {v}" if str(v).strip()!='' else 'Unknown')
    elif naics_like:
      naics_col = naics_like[0]
      df_reg['naics_group'] = df_reg[naics_col].fillna('Unknown').astype(str)
    else:
      df_reg['naics_group'] = 'Unknown'

    # build top-industry grouping similar to plotting
    top_naics = df_reg['naics_group'].value_counts().nlargest(10).index.tolist()
    df_reg['naics_top'] = df_reg['naics_group'].where(df_reg['naics_group'].isin(top_naics), 'Other')

    # create binary indicator: whether the posting requires ML/DS skills
    # keep `is_ml_job` for backwards compatibility with the formula
    df_reg['requires_ml_skill'] = df_reg.get('ml_skill_count', 0) > 0
    df_reg['is_ml_job'] = df_reg['requires_ml_skill']

    df_reg['log_salary'] = np.log(df_reg['salary_num'].astype(float))

    # add simple controls if missing
    if 'n_skills' not in df_reg.columns:
      df_reg['n_skills'] = df_reg.get('all_skill_tokens', []).apply(lambda x: len(x) if isinstance(x, (list, tuple)) else 0)
    if 'ml_skill_count' not in df_reg.columns:
      df_reg['ml_skill_count'] = 0

    # Fit OLS with industry fixed effects and interaction: log_salary ~ is_ml_job * C(naics_top) + n_skills + ml_skill_count
    formula = 'log_salary ~ is_ml_job * C(naics_top) + n_skills + ml_skill_count'
    try:
      model = smf.ols(formula=formula, data=df_reg).fit(cov_type='HC3')
      print(model.summary())
      # save summary to file
      with open('figures/ols_summary.txt', 'w') as f:
        f.write(model.summary().as_text())
    except Exception as e:
      print('Regression failed:', e)
      model = None

    # If model fit, compute predicted salaries for ML vs non-ML by industry
    if model is not None:
      preds = []
      # use mean of numeric controls for prediction
      mean_n_skills = df_reg['n_skills'].mean() if 'n_skills' in df_reg.columns else 0
      mean_ml_skill_count = df_reg['ml_skill_count'].mean() if 'ml_skill_count' in df_reg.columns else 0

      for ind in df_reg['naics_top'].unique():
        for ml_flag in [0,1]:
          # model expects `is_ml_job` variable (we set it above), so pass that for prediction
          row = { 'is_ml_job': ml_flag, 'n_skills': mean_n_skills, 'ml_skill_count': mean_ml_skill_count, 'naics_top': ind }
          try:
            pred_res = model.get_prediction(pd.DataFrame([row]))
            pred_mean_log = pred_res.predicted_mean[0]
            pred_mean = float(np.exp(pred_mean_log))
          except Exception:
            pred_mean = np.nan
          preds.append({'naics_top': ind, 'is_ml_job': bool(ml_flag), 'predicted_salary': pred_mean})

      pred_df = pd.DataFrame(preds).dropna()
      # sort industries by total postings to keep consistent order
      order = df_reg['naics_top'].value_counts().loc[lambda x: x.index.isin(pred_df['naics_top'])].index.tolist()
      pred_df['naics_top'] = pd.Categorical(pred_df['naics_top'], categories=order, ordered=True)

  # Map boolean to readable labels and plot side-by-side bars for predicted salary by industry
  pred_df['requires_label'] = pred_df['is_ml_job'].map({True: 'Jobs requiring ML/DS skills', False: 'Jobs not requiring ML/DS skills'})
  plt.figure(figsize=(14,7))
  sns.barplot(data=pred_df, x='naics_top', y='predicted_salary', hue='requires_label')
  plt.xlabel('Industry (top)')
  plt.ylabel('Predicted Salary (USD)')
  plt.title('Predicted salary by industry — Jobs requiring ML/DS skills vs not (controls at mean)')
  plt.xticks(rotation=25, ha='right')
  plt.legend(title='Requirement')
  plt.tight_layout()
  out_png2 = 'figures/regression_predicted_salary_by_industry.png'
  plt.savefig(out_png2, dpi=220)
  print('Saved regression predicted-salary figure to', out_png2)

``` 

# Analysis
Based on the KMeans clustering, we expected to see higher salaries across industries for roles requiring machine learning and data science skills. However, the regression results showed that only Information and Retail Trade—along with “Other”—had higher salaries for jobs requiring those skills. This suggests that while job postings requiring ML/DS skills tend to include higher salary outliers, the overall demand for these skills may still be relatively niche. In many industries, organizations may not yet know how to fully incorporate machine learning and data science into their operations, meaning that the highest-paying roles still emphasize more traditional skill sets. It’s likely that performing this same analysis five or ten years from now would yield very different results as these skills become more widely adopted and in demand across currently slower-to-adapt industries.